{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 0. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"peers.csv\")[[\"airline_code\",\"review\",\"recommended\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_code</th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>it has managed to avoid paying. Florence to Lo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>was one of my favourite airlines.  D端sseldorf ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>very positive experience.  Milan to New York r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_code                                             review  recommended\n",
       "0   air-berlin  it has managed to avoid paying. Florence to Lo...          0.0\n",
       "1   air-berlin  was one of my favourite airlines.  D端sseldorf ...          0.0\n",
       "2   air-berlin  very positive experience.  Milan to New York r...          1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3626    Seat was fine with enough legroom.  Dusseldorf...\n",
       "3627    crew were smiling and good.  Berlin to Dusseld...\n",
       "3628    only two agents available. Check in process at...\n",
       "3629    good flight and friendly staff.  Amsterdam to ...\n",
       "3630    never been treated as badly.  I have been a fr...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germanwings = df[df.airline_code==\"germanwings\"].review\n",
    "germanwings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_code</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british-airways</td>\n",
       "      <td>2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eurowings</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germanwings</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>klm-royal-dutch-airlines</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>niki</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ryanair</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vueling-airlines</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               airline_code  review\n",
       "0                air-berlin     488\n",
       "1           british-airways    2863\n",
       "2                 eurowings     275\n",
       "3               germanwings     146\n",
       "4  klm-royal-dutch-airlines    1002\n",
       "5                      niki      42\n",
       "6                   ryanair    1610\n",
       "7          vueling-airlines     967"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"airline_code\", as_index=False)[\"review\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_code</th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>it has managed to avoid paying. Florence to Lo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>was one of my favourite airlines.  D端sseldorf ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>very positive experience.  Milan to New York r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>Definitely avoid if you can.  Berlin to Prague...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>happy their service.  Frankfurt to Berlin, our...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_code                                             review  recommended\n",
       "0   air-berlin  it has managed to avoid paying. Florence to Lo...          0.0\n",
       "1   air-berlin  was one of my favourite airlines.  D端sseldorf ...          0.0\n",
       "2   air-berlin  very positive experience.  Milan to New York r...          1.0\n",
       "3   air-berlin  Definitely avoid if you can.  Berlin to Prague...          0.0\n",
       "4   air-berlin  happy their service.  Frankfurt to Berlin, our...          1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.airline_code!=\"nikki\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_code</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>it has managed to avoid paying. Florence to Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british-airways</td>\n",
       "      <td>outstanding courtesy and service. I would like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eurowings</td>\n",
       "      <td>avoided like the plague. Rome to Vienna, I nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germanwings</td>\n",
       "      <td>Seat was fine with enough legroom.  Dusseldorf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>klm-royal-dutch-airlines</td>\n",
       "      <td>Stay away from KLM. Frankfurt to Saint Petersb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               airline_code                                             review\n",
       "0                air-berlin  it has managed to avoid paying. Florence to Lo...\n",
       "1           british-airways  outstanding courtesy and service. I would like...\n",
       "2                 eurowings  avoided like the plague. Rome to Vienna, I nee...\n",
       "3               germanwings  Seat was fine with enough legroom.  Dusseldorf...\n",
       "4  klm-royal-dutch-airlines  Stay away from KLM. Frankfurt to Saint Petersb..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressed_reviews = df.groupby(\"airline_code\", as_index=False)[\"review\"].agg({\"review\": lambda x: \"%s\" % ' '.join(x)[::]})\n",
    "pressed_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seat was fine with enough legroom.  Dusseldorf to Berlin. Eurowings flight operated by Germanwings EW9050. Flight had a slight delay of 15 minutes. Flight was smooth and good. Seat was fine with enough legroom. Food and drinks for puchase, crew was just average. crew were smiling and good.  Berlin t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressed_germanwings = pressed_reviews[pressed_reviews.airline_code==\"germanwings\"].review.iloc[0]\n",
    "pressed_germanwings[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "extra_stopwords = ['flight','seat','time', 'Airline','klm','passenger','passengers','flight','airport','airline']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic Modeling ##\n",
    "LDA: Latent Dirichlet Allocation Model\n",
    "* Identifies potential topics using pruning techniques\n",
    "* Computes conditional probabilities for topic word sets\n",
    "* Identifies the most likely topics\n",
    "* Does this over multiple passes probabilistically picking topics in each pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Data Preprocessing\n",
    "We will perform the following steps:\n",
    "\n",
    "* **Tokenization**: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* All **stopwords** are removed.\n",
    "* Words are **lemmatized** - words in third person are changed to first person and verbs in past and future tenses are changed into present (eg. went -> go).\n",
    "* Words are **stemmed** - words are reduced to their root form (eg. dies, died, dead -> die)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    import gensim\n",
    "    from gensim.utils import simple_preprocess\n",
    "    from nltk.corpus import stopwords\n",
    "    newstopwords = stopwords.words(\"english\")\n",
    "    try:\n",
    "        newstopwords.extend(extra_stopwords)\n",
    "    except:\n",
    "        pass\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in newstopwords and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def topic_modeling(documents,num_topics=3, passes = 4,workers=4, num_words=3): \n",
    "    processed_docs = documents.map(preprocess)\n",
    "    import gensim.corpora\n",
    "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "    # Remove very rare and very common words\n",
    "    #dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)\n",
    "    #Create the Bag-of-words model for each document\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "    ## 3.2: TF-IDF \n",
    "    from gensim import corpora, models\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                           num_topics=num_topics, \n",
    "                                           id2word = dictionary, \n",
    "                                           passes = passes, \n",
    "                                           workers=workers)\n",
    "\n",
    "    for idx, topic in lda_model.print_topics(num_words=num_words):\n",
    "        print(\"* Topic {}: {}\".format(idx+1, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Topic 1: 0.017*\"germanw\" + 0.010*\"servic\" + 0.010*\"lufthansa\"\n",
      "* Topic 2: 0.015*\"crew\" + 0.014*\"cabin\" + 0.012*\"germanw\"\n",
      "* Topic 3: 0.023*\"germanw\" + 0.010*\"staff\" + 0.010*\"delay\"\n"
     ]
    }
   ],
   "source": [
    "topic_modeling(germanwings,num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Reviews of  air-berlin\n",
      "* Topic 1: 0.027*\"berlin\" + 0.013*\"servic\" + 0.011*\"busi\"\n",
      "* Topic 2: 0.029*\"berlin\" + 0.011*\"servic\" + 0.010*\"seat\"\n",
      "\n",
      "** Reviews of  british-airways\n",
      "* Topic 1: 0.013*\"servic\" + 0.012*\"crew\" + 0.011*\"seat\"\n",
      "* Topic 2: 0.011*\"servic\" + 0.011*\"airway\" + 0.010*\"london\"\n",
      "\n",
      "** Reviews of  eurowings\n",
      "* Topic 1: 0.017*\"eurow\" + 0.010*\"hour\" + 0.009*\"delay\"\n",
      "* Topic 2: 0.019*\"eurow\" + 0.014*\"delay\" + 0.013*\"servic\"\n",
      "\n",
      "** Reviews of  germanwings\n",
      "* Topic 1: 0.018*\"germanw\" + 0.011*\"good\" + 0.011*\"check\"\n",
      "* Topic 2: 0.015*\"germanw\" + 0.011*\"delay\" + 0.009*\"crew\"\n",
      "\n",
      "** Reviews of  klm-royal-dutch-airlines\n",
      "* Topic 1: 0.017*\"amsterdam\" + 0.014*\"servic\" + 0.013*\"good\"\n",
      "* Topic 2: 0.015*\"amsterdam\" + 0.014*\"seat\" + 0.011*\"servic\"\n",
      "\n",
      "** Reviews of  niki\n",
      "* Topic 1: 0.020*\"drink\" + 0.020*\"free\" + 0.019*\"niki\"\n",
      "* Topic 2: 0.017*\"check\" + 0.013*\"return\" + 0.011*\"vienna\"\n",
      "\n",
      "** Reviews of  ryanair\n",
      "* Topic 1: 0.023*\"ryanair\" + 0.012*\"board\" + 0.011*\"check\"\n",
      "* Topic 2: 0.025*\"ryanair\" + 0.015*\"board\" + 0.012*\"check\"\n",
      "\n",
      "** Reviews of  vueling-airlines\n",
      "* Topic 1: 0.026*\"vuel\" + 0.020*\"hour\" + 0.016*\"delay\"\n",
      "* Topic 2: 0.016*\"vuel\" + 0.013*\"seat\" + 0.012*\"check\"\n"
     ]
    }
   ],
   "source": [
    "for airline_code in df.airline_code.unique().tolist():\n",
    "    print(\"\\n** Reviews of \",airline_code)\n",
    "    text = df[df.airline_code==airline_code].review\n",
    "    topic_modeling(text,num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Simple sentiment analysis</h3>\n",
    "Compute the proportion of positive and negative words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_words(url):\n",
    "    \"\"\"\n",
    "    Get sentiment coded words from Hu and Liu's sentiment analysis lexicon.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    words = requests.get(url).content.decode('latin-1')\n",
    "    word_list = words.split('\\n')\n",
    "    index = 0\n",
    "    while index < len(word_list):\n",
    "        word = word_list[index]\n",
    "        if ';' in word or not word:\n",
    "            word_list.pop(index)\n",
    "        else:\n",
    "            index+=1\n",
    "    return word_list\n",
    "\n",
    "#Get lists of positive and negative words\n",
    "p_url = 'http://ptrckprry.com/course/ssd/data/positive-words.txt'\n",
    "n_url = 'http://ptrckprry.com/course/ssd/data/negative-words.txt'\n",
    "positive_words = get_words(p_url)\n",
    "negative_words = get_words(n_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+', 'abound', 'abounds', 'abundance', 'abundant']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_code</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-berlin</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british-airways</td>\n",
       "      <td>2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eurowings</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germanwings</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>klm-royal-dutch-airlines</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>niki</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ryanair</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vueling-airlines</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               airline_code  review\n",
       "0                air-berlin     488\n",
       "1           british-airways    2863\n",
       "2                 eurowings     275\n",
       "3               germanwings     146\n",
       "4  klm-royal-dutch-airlines    1002\n",
       "5                      niki      42\n",
       "6                   ryanair    1610\n",
       "7          vueling-airlines     967"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"airline_code\", as_index=False).review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def pos_neg_freq(text):\n",
    "    \"\"\"\n",
    "    Compute sentiment by looking at the proportion of positive and negative words in the text.\n",
    "    \"\"\"\n",
    "    from nltk import word_tokenize\n",
    "    pos = neg = 0\n",
    "    for word in word_tokenize(text):\n",
    "        if word in positive_words:\n",
    "            pos+=1\n",
    "        if word in negative_words:\n",
    "            neg+=1\n",
    "    return { \"Positive\": round(pos/len(word_tokenize(text))*100,1),\n",
    "            \"Negative\": round(neg/len(word_tokenize(text))*100,1),\n",
    "            \"Net\": round((pos-neg)/len(word_tokenize(text))*100,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def pos_neg_freg_documents(documents):\n",
    "    \"\"\"\n",
    "    Compute sentiment dor the data frame by using pos_neg_freq() funciton.\n",
    "    \"\"\"\n",
    "    freq_list = []\n",
    "    for (review,airline_code) in zip(documents[\"review\"], documents[\"airline_code\"]):\n",
    "        freq_dict = {\"airline_code\" : airline_code}\n",
    "        freq_dict.update(pos_neg_freq(review))\n",
    "        freq_list.append(freq_dict)\n",
    "    freq_list = freq_list[-1:] + freq_list[:-1]\n",
    "    freq = pd.DataFrame.from_dict(freq_list)\n",
    "    return freq[[\"airline_code\",\"Positive\",\"Negative\",\"Net\"]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pos_neg = pos_neg_freg_documents(pressed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple sentiment analysis using NRC data\n",
    "NRC data codifies words with emotions where 14,182 words are coded into 2 sentiments and 8 emotions. For example, the word abandonment is associated with anger, fear, sadness and has a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rear the NRC sentiment data.\n",
    "\"\"\"\n",
    "nrc = \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n",
    "count=0\n",
    "emotion_dict=dict()\n",
    "with open(nrc,'r') as f:\n",
    "    all_lines = list()\n",
    "    for line in f:\n",
    "        if count < 46:\n",
    "            count+=1\n",
    "            continue\n",
    "        line = line.strip().split('\\t')\n",
    "        if int(line[2]) == 1:\n",
    "            if emotion_dict.get(line[0]):\n",
    "                emotion_dict[line[0]].append(line[1])\n",
    "            else:\n",
    "                emotion_dict[line[0]] = [line[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'negative', 'sadness']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict['abandoned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anticipation': 0.02571191595244684,\n",
       " 'anger': 0.006773569256289754,\n",
       " 'fear': 0.008501520597179998,\n",
       " 'joy': 0.017348631462538053,\n",
       " 'trust': 0.029858999170583427,\n",
       " 'surprise': 0.009469173348078536,\n",
       " 'negative': 0.023223666021564886,\n",
       " 'positive': 0.03939729057229758,\n",
       " 'sadness': 0.012164777439867318,\n",
       " 'disgust': 0.004561791539950241}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotion_analyzer(text,emotion_dict=emotion_dict):\n",
    "    \"\"\"\n",
    "    Analize 8 emotions and 2 sentiments using NRC data.\n",
    "    \"\"\"\n",
    "    #Set up the result dictionary\n",
    "    emotions = {x for y in emotion_dict.values() for x in y}\n",
    "    # print(type(emotions),emotions)\n",
    "    emotion_count = dict()\n",
    "    for emotion in emotions:\n",
    "        emotion_count[emotion] = 0\n",
    "\n",
    "    #Analyze the text and normalize by total number of words\n",
    "    total_words = len(text.split())\n",
    "    for word in text.split():\n",
    "        if emotion_dict.get(word):\n",
    "            for emotion in emotion_dict.get(word):\n",
    "                emotion_count[emotion] += 1/len(text.split())\n",
    "    #rounding the values in emotion_count\n",
    "    return emotion_count\n",
    "\n",
    "emotion_analyzer(pressed_reviews[\"review\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def emotion_analyzer_documents(documents):\n",
    "    \"\"\"\n",
    "    Analize emotions and sentiments for data frame.\n",
    "    \"\"\"\n",
    "    freq_list = []\n",
    "    for (review,airline_code) in zip(documents[\"review\"], documents[\"airline_code\"]):\n",
    "        freq_dict = {\"airline_code\" : airline_code}\n",
    "        freq_dict.update(emotion_analyzer(review))\n",
    "        freq_list.append(freq_dict)\n",
    "    freq_list = freq_list[-1:] + freq_list[:-1]\n",
    "    freq = pd.DataFrame.from_dict(freq_list).round(2)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-59491204bbda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotion_analyzer_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpressed_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-170bd6991363>\u001b[0m in \u001b[0;36memotion_analyzer_documents\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mairline_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"airline_code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfreq_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"airline_code\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mairline_code\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfreq_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mfreq_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfreq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-79ec00566eec>\u001b[0m in \u001b[0;36memotion_analyzer\u001b[0;34m(text, emotion_dict)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0memotion_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotion_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0memotion_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#rounding the values in emotion_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0memotion_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emotions = emotion_analyzer_documents(pressed_reviews)\n",
    "emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Clouds\n",
    "Let's See what sort of words reviews use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "seperated_documents = df.groupby([\"airline_code\",\"recommended\"], as_index=False)[\"review\"].agg({\"review\": lambda x: \"%s\" % ' '.join(x)})\n",
    "seperated_documents.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "seperated_documents[seperated_documents[\"airline_code\"]==\"germanwings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pos = seperated_documents.loc[(seperated_documents[\"airline_code\"] == \"germanwings\") &\n",
    "                    (seperated_documents[\"recommended\"] == 1), \"review\"].values[0]\n",
    "neg = seperated_documents.loc[(seperated_documents[\"airline_code\"] == \"germanwings\") &\n",
    "                    (seperated_documents[\"recommended\"] == 0), \"review\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def wordcloud(text, background_color='white', max_words=50):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.style.use(['dark_background'])\n",
    "    from wordcloud import WordCloud\n",
    "    from nltk.corpus import stopwords\n",
    "    newstopwords = stopwords.words(\"english\")\n",
    "    try:\n",
    "        newstopwords.extend(extra_stopwords)\n",
    "    except:\n",
    "        pass\n",
    "    wc = WordCloud(background_color=background_color, max_words=max_words,\n",
    "                   stopwords = newstopwords)\n",
    "    # Generate and plot wordcloud\n",
    "    plt.imshow(wc.generate(text))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Positive reviews of Germanwings\")\n",
    "wordcloud(pos)\n",
    "print(\"Negative reviews of Germanwings\")\n",
    "wordcloud(neg, background_color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for (review,airline_code) in zip(pressed_reviews[\"review\"], pressed_reviews[\"airline_code\"]):\n",
    "    print(\"Reviews of \",airline_code)\n",
    "    wordcloud(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization ##\n",
    "Text summarization is useful because you can generate a short summary of a large piece of text automatically. These summaries can serve as an input into a topic analyzer to figure out what the main topic of the text is. A naive form of summarization is to identify the most frequent words in a piece of text and use the occurrence of these words in sentences to rate the importance of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summariser(text):\n",
    "    \"\"\"\n",
    "    Naive summarizer: Identify the most frequent words in a piece of text \n",
    "    and use the occurrence of these words in sentences \n",
    "    to rate the importance of a sentence.\n",
    "    \"\"\"\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    from nltk.probability import FreqDist\n",
    "    from nltk.corpus import stopwords\n",
    "    from collections import OrderedDict\n",
    "    summary_sentences = []\n",
    "    candidate_sentences = {}\n",
    "    candidate_sentence_counts = {}\n",
    "    striptext = text.replace('\\n\\n', ' ')\n",
    "    striptext = striptext.replace('\\n', ' ')\n",
    "    words = word_tokenize(striptext)\n",
    "    from nltk.corpus import stopwords\n",
    "    newstopwords = stopwords.words(\"english\")\n",
    "    try:\n",
    "        newstopwords.extend(extra_stopwords)\n",
    "    except:\n",
    "        pass\n",
    "    lowercase_words = [word.lower() for word in words\n",
    "                      if word not in newstopwords and word.isalpha() ]\n",
    "    word_frequencies = FreqDist(lowercase_words)\n",
    "    most_frequent_words = FreqDist(lowercase_words).most_common(20)\n",
    "    sentences = sent_tokenize(striptext)\n",
    "    for sentence in sentences:\n",
    "        candidate_sentences[sentence] = sentence.lower()\n",
    "    for long, short in candidate_sentences.items():\n",
    "        count = 0\n",
    "        for freq_word, frequency_score in most_frequent_words:\n",
    "            if freq_word in short:\n",
    "                count += frequency_score\n",
    "                candidate_sentence_counts[long] = count   \n",
    "    sorted_sentences = OrderedDict(sorted(\n",
    "                        candidate_sentence_counts.items(),\n",
    "                        key = lambda x: x[1],\n",
    "                        reverse = True)[:4])\n",
    "    return sorted_sentences   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.summarization\n",
    "print(gensim.summarization.summarize(pressed_germanwings, word_count=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizer based on lexical similarity: gensim ##\n",
    "Gensim uses a network with sentences as nodes and 'lexical similarity' as weights on the arcs between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(summariser(pressed_germanwings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
